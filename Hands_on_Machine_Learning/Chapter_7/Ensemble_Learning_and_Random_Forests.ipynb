{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlrg0eyH3qD2SOKGXzg7nK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matinsalami/DataScience/blob/main/Hands_on_Machine_Learning/Chapter_7/Ensemble_Learning_and_Random_Forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A group of predictors are called **Ensemble** and using this ensemble to get a better prediction on a dataset is called **Ensemble Learning**. An Ensemble Learning algorithm is called an Ensemble method. Here se discuss different methods for regressors and classifiers.  "
      ],
      "metadata": {
        "id": "Nhog-k4rdogo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Voting Classifiers"
      ],
      "metadata": {
        "id": "kIIY4u2xeZrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having trained a number of different classifiers on a dataset(SVM, Random Forest, K-Nearest Neighbors e.g.), a very simple way to have a better classifier is to aggregate the predictions pf each classifier and predict the class that gets the most votes. This new classifier seems to achieve better accuracy even if each classifier in the ensemble is weak learner, the ensemble can still be a strong learner provided there are a sufficient number of weak learners and they are sufficiently diverse.\n",
        "\n",
        "Note: Ensemble methods ork best when the predictors are as independent from one another as possible. One way to get diverse classifiers is to train them using different algorithms. This increases the chance that they will make very different types of errors, improving the ensemble's accuracy."
      ],
      "metadata": {
        "id": "yqAQZg2KeeyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an example of hard-voting classifier:"
      ],
      "metadata": {
        "id": "KSMWNpkZfidV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G97m4UV2biWZ",
        "outputId": "1b361e19-6d54-4b83-a085-186e47e22b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  1.0\n",
            "Accuracy:  1.0\n",
            "Accuracy:  1.0\n",
            "Accuracy:  1.0\n",
            "Accuracy:  1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define base classifiers\n",
        "clf1 = LogisticRegression(max_iter=1000)\n",
        "clf2 = DecisionTreeClassifier()\n",
        "clf3 = SVC(probability=False)  # no need for probabilities in hard voting\n",
        "clf4 = RandomForestClassifier()\n",
        "\n",
        "# Create hard voting ensemble\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', clf1), ('dt', clf2), ('svc', clf3), ('rf', clf4)],\n",
        "    voting='hard'  # 'hard' = majority voting\n",
        ")\n",
        "\n",
        "# Train the ensemble\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "for clf in (clf1,clf2,clf3,clf4,voting_clf):\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(\"Accuracy: \", accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If all the classifiers in the ensemble have a dict_proba() method, meaning they are able to estimate class probabilities, we can use soft voting classifier. It often achieves higher performance than hard voting classifier because it gives more weight to highly confident votes. In Scikit-Learn you only need to replace `voting=\"hard\"` with `voting=\"soft\"`.\n",
        "\n",
        "Note: In SVM you need to set its `probability` hyperparameter to `True`.  "
      ],
      "metadata": {
        "id": "fBBeONAdmD_r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9PQo5kQ0jRHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}